{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BUr_7GVHZT"
      },
      "source": [
        "# **GE - TP: Segmentation avec PyTorch**\n",
        "\n",
        "\n",
        "Dans ce TP, nous allons coder un réseau de neurones pour segmenter des tumeurs sur des scan de cerveau.\n",
        "\n",
        "\n",
        "Try comparison with UNet ++ https://github.com/MrGiovanni/UNetPlusPlus\n",
        "or just add residual connections.\n",
        "Add visualization during the training.\n",
        "\n",
        "\n",
        "- Explore functions in Sitk\n",
        "- Define hyperparameters\n",
        "- Dataset split\n",
        "- ConvBatchNorm\n",
        "- How to import from github ?\n",
        "\n",
        "One additional model\n",
        "- either integrating a new model from model, train it and compare\n",
        "- or show benefits from pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB4W-Jw9VHZn"
      },
      "source": [
        "# **1. Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13YDHJHyC8td"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.utils.tensorboard\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as model_selection\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "\n",
        "!pip install tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t2qfPU3VHZx"
      },
      "source": [
        "# **2. Database**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO_00VNxVqB_"
      },
      "source": [
        "## 2.a. Télécharger la base de données.\n",
        "\n",
        "Exécutez la cellule suivante pour télécharger la base de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPENhQdf3QrC"
      },
      "source": [
        "!git clone https://github.com/soniamartinot/GEP1.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/soniamartinot/MVADLMI_TP3.git"
      ],
      "metadata": {
        "id": "j61_jxGrYoAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io16YVeDYE0G"
      },
      "source": [
        "## 2.b. Aperçu de la base de données.\n",
        "\n",
        "Les données se trouvent dans le dossier `/GEP1/`.\n",
        "\n",
        "Dans ce dossier, vous trouverez:\n",
        "\n",
        "> Le dossier `origin_data` : contient 4 patients.\n",
        ">- Pour chaque patient, vous trouverez un volume entier par modalité sous format nifti.\n",
        ">- Chaque volume est de taille `(155, 192, 192)`\n",
        "\n",
        "> Le dossier `data` contient 336 patients.\n",
        ">- Les images dans ce dossier ont été pré-traitées et ont maintenant une taille de `(78, 96, 96)`. La taille plus petite rendra l'entraînement des modèles plus rapide et moins gourmand en ressoures.\n",
        ">- Si on considère un patient `BraTS19_EXAMPLE`, son dossier s'appellera `/GEP1/data/BraTS19_EXAMPLE`. Dans ce dossier, vous trouverez des fichiers nifti (`.nii.gz`) pour chaque modalité, et pour chaque coupe selon l'axe Z.\n",
        ">- Il y a 78 coupes par volume, i.e. 78 coupes par modalité.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJZ7vV9UVHZ7"
      },
      "source": [
        "# The data is store in the folder /GEP1/\n",
        "data_path = './GEP1/data/'\n",
        "original_data_path = './GEP1/origin_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPUuRxOHVHaA"
      },
      "source": [
        "### **i. Contenu de la base de données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSV6BYfEVHaD"
      },
      "source": [
        "# Original data\n",
        "print(\"Content of the folder:\\n\", os.listdir(original_data_path))\n",
        "patient = \"BraTS19_TCIA01_131_1\"\n",
        "print(\"Content of a patient's folder:\\n\", os.listdir(original_data_path + patient))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1SY6hSVHaH"
      },
      "source": [
        "# Processed data\n",
        "files = os.listdir(data_path) # All the files in the folder /GEP1/data/\n",
        "print('Content of the folder {} \\n: {}'.format(data_path, files[:5]))\n",
        "print('Number of files for each patient : {}'.format(len(os.listdir(data_path + files[0])) ))\n",
        "print('Number of patients in {} : {}'.format(data_path, len(files)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JsQbnkhVHaK"
      },
      "source": [
        "### **ii. Contenu du dossier d'un patient**\n",
        "\n",
        "Pour chaque patient, vous trouverez 4 modalités et les masques de segmentation:\n",
        "\n",
        "- t1\n",
        "- t2\n",
        "- flair\n",
        "- t1ce (gado)\n",
        "- seg\n",
        "    \n",
        "Pour chqaue modalité, vous trouverez un fichier pour chaque coupe selon l'axe Z. Chaque patient a **78 coupes** par modalité."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqWxq524VHaM"
      },
      "source": [
        "modalities = ['t1', 't2', 't1ce', 'flair', 'seg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI1kupGTVHaS"
      },
      "source": [
        "patient = 'BraTS19_2013_20_1'\n",
        "patient_path = os.path.join(data_path, patient)\n",
        "patient_files = os.listdir(patient_path)\n",
        "patient_files[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLQ4JtRjVHaV"
      },
      "source": [
        "\"\"\"\n",
        "Filter for the Flair modality\n",
        "\"\"\"\n",
        "\n",
        "flair_modality_files = sorted([e for e in patient_files if 'flair' in e])\n",
        "print(\"Number of Z slices:\", len(flair_modality_files))\n",
        "flair_modality_files[-5:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmGMQt78VHaY"
      },
      "source": [
        "### **iii. SimpleITK tutorial**\n",
        "\n",
        "On utilise le package Python `SimpleITK` pour lire les fichiers nifti de la base de données.\n",
        "\n",
        "Pour ouvrir une image nifti, il faut utiliser la fonction suivante:\n",
        "\n",
        "        image = sitk.ReadImage(image_path)\n",
        "\n",
        "Grâce à ce package, vous avez accès à des informations pertinentes, physiques ou médicales, sur chaque image:\n",
        "- spacing: `image.GetSpacing()`\n",
        "- direction: `image.GetDirection()`\n",
        "- origine: `image.GetOrigin()`\n",
        "- taille: `image.GetSize()`\n",
        "- metadata: `image.GetMetaDataKeys()`\n",
        "- valeur d'un pixel: `image.GetPixel(pixel_x, pixel_y, pixel_z)`\n",
        "\n",
        "Vous pouvez passer d'une image `sitk` à un array `numpy` grâce à la commande suivante:\n",
        "\n",
        "        array = sitk.GetArrayFromImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDUJ-IhVHaZ"
      },
      "source": [
        "patient = 'BraTS19_CBICA_ANP_1'\n",
        "\n",
        "# Define the image path\n",
        "z = 3\n",
        "modality = 'flair'\n",
        "patient_folder = os.path.join(original_data_path, patient)\n",
        "image_name = \"{patient}_{modality}.nii.gz\".format(patient=patient, modality=modality)\n",
        "image_path = os.path.join(patient_folder, image_name)\n",
        "print(\"Path to the image:\", image_path)\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(image_path)\n",
        "print(\"Type of the opened image:\", type(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bZqYuD4VHab"
      },
      "source": [
        "# Print geometrical information\n",
        "print('Image Direction : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Spacing : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Origin : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Size : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Pixel value:', \"\"\"Complete here\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vADXJEgjVHad"
      },
      "source": [
        "# Get all the information in the meta data\n",
        "keys = image.GetMetaDataKeys()\n",
        "print('Metadata :')\n",
        "for key in keys:\n",
        "    print('{} : {}'.format(key, image.GetMetaData(key)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldR6c6E6VHae"
      },
      "source": [
        "# Convert the sitk image\n",
        "array = sitk.GetArrayFromImage(image)\n",
        "print(\"Type of the image:\", type(array)) # Type of the image\n",
        "print(\"Shape of the image as a numpy array:\", array.shape)\n",
        "print(\"Value of the first pixel of the numpy array:\", array[0, 0, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcfaqwSVHah"
      },
      "source": [
        "### **iv. Comparaison entre les données originales et pré-traitées.**\n",
        "\n",
        "\n",
        "Afin d'accélérer les temps de calcul pour obtenir de bons résultats plus rapidement, les images d'origine de taille `(155, 240, 240)` ont été pré-traitées selon les étapes suivantes:\n",
        "- Crop les images à la taille `(155, 192, 192)`\n",
        "- Réduire la résolution des images par interpolation d'échelle 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) jusqu'à une taille de `(78, 96, 96)`\n",
        "- Sauvegarder les coupes de l'axe Z de façon **indépendemment** les unes des autres dans de nouveaux array de taille `(96, 96)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wswI0m1NVHai"
      },
      "source": [
        "patient = 'BraTS19_CBICA_ANP_1'\n",
        "\n",
        "# Define the image path in the original data\n",
        "z = 3\n",
        "modality = 'flair'\n",
        "patient_folder = os.path.join(original_data_path, patient)\n",
        "image_name = \"{patient}_{modality}.nii.gz\".format(patient=patient, modality=modality)\n",
        "image_path = os.path.join(patient_folder, image_name)\n",
        "\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(image_path)\n",
        "\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "\n",
        "print('Original array shape : {}'.format(orig_array.shape))\n",
        "\n",
        "# open corresponding preprocessed data slice\n",
        "patient_folder = os.path.join(data_path, patient)\n",
        "z_slice = 35\n",
        "path = os.path.join(patient_folder, \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice))\n",
        "processed_image = sitk.ReadImage(path)\n",
        "\n",
        "processed_array = sitk.GetArrayFromImage(processed_image)\n",
        "\n",
        "print('Processed array shape : {}'.format(processed_array.shape))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('Original array')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_array, cmap='gray')\n",
        "plt.title('Processed array')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXW-yIHeVHak"
      },
      "source": [
        "### **v. Visualiser toutes les modalités.**\n",
        "\n",
        "\n",
        "Considérons un patient dans le dossier `data`. Plot chaque modalité côte à côte en itérant sur les coupes Z disponibles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7OYGY8_VHal"
      },
      "source": [
        "# Go over each Z slice\n",
        "for z in range(len(flair_modality_files)):\n",
        "    f, axes = plt.subplots(1, 5, figsize=(20, 6))\n",
        "\n",
        "    # Plot each modality for that slice\n",
        "    for i, modality in enumerate(modalities):\n",
        "        # Fetch the modality-slice file and open using SimpleITK\n",
        "        file_path = data_path + \"{patient}/{patient}_{modality}_z_{z}.nii.gz\".format(patient=patient, modality=modality, z=z)\n",
        "        slice = sitk.GetArrayFromImage(sitk.ReadImage(file_path))\n",
        "\n",
        "        # Plot the slice\n",
        "        axes[i].set_title(modality)\n",
        "        axes[i].imshow(slice, cmap=\"gray\")\n",
        "\n",
        "    plt.suptitle(\"Slice {}/{}\".format(z+1, len(flair_modality_files)), y=0.85)\n",
        "    plt.show()\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfFJKex5VHan"
      },
      "source": [
        "## 2.c. Création des train, validation et test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWzV-qrfZ0nk"
      },
      "source": [
        "\n",
        "Les train, validation et test sets sont indiqués dans le dossier `/GEP1/datasets`. Pour chaque set, vous trouverez un fichier texte contenant une liste de patients à inclure dans le set.\n",
        "\n",
        "\n",
        "Exécutez le code suivant afin de:\n",
        "*   Charger les train, validation et test sets.\n",
        "*   Afficher les 5 premiers patients du train set.\n",
        "*   Afficher la longueur des train, validation et test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1nxaDK_Z1AS"
      },
      "source": [
        "datasets_path = './GEP1/datasets/'\n",
        "\n",
        "train_set = np.loadtxt(datasets_path + 'train.txt', dtype=str)\n",
        "validation_set = np.loadtxt(datasets_path + 'val.txt', dtype=str)\n",
        "test_set = np.loadtxt(datasets_path + 'test.txt', dtype=str)\n",
        "\n",
        "# Train_set, validation_set and test_set are list of patients\n",
        "print('Train set, first 5 patients : {}\\n'.format(train_set[:5])) # Print the first 5 patients of train_set\n",
        "print('Train set length :\\t {}'.format(len(train_set)))\n",
        "print('Validation set length :\\t {}'.format(len(validation_set)))\n",
        "print('Test set length :\\t {}'.format(len(test_set)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcVUj8KuXXfN"
      },
      "source": [
        "# **3. Creation du réseau de neurones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVPBwaDZnFx"
      },
      "source": [
        "Dans cette partie, nous allons coder un [**UNet**](https://arxiv.org/pdf/1505.04597.pdf). Les UNets sont particulièrement utilisés pour des tâches de segmentation dans le domaine de l'imagerie médicale. Vous pouvez étudier son architecture dans la figure suivante.\n",
        "\n",
        "Le UNet a deux principales caractéristiques:\n",
        "\n",
        "1.   La taille de l'image d'entrée est divisée par 2 à chaque bloc par une couche appelée `MaxPooling` dans la partie **encoder** du modèle. dans la partie **decoder**, les features extraites sont progressivement suréchantillonnées par des Transpose Convolution  (`ConvTranspose2d` in PyTorch) jusqu'à retrouver la taille de l'image d'entrée.\n",
        "\n",
        "2.   Afin de conserver des informations de haute résolution, le modèle est doté de **skip-connections** qui passent de l'information entre l'encoder et le decoder.\n",
        "\n",
        "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qDJ20x-8jPJ"
      },
      "source": [
        "## 3.a. Création du réseau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjY5Q--3VHat"
      },
      "source": [
        "### **i. Building blocks**\n",
        "\n",
        "Que fait la fonction `get_activation` ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq0jSmv2VHat"
      },
      "source": [
        "def get_activation(activation_type):\n",
        "    activation_type = activation_type.lower()\n",
        "    if hasattr(nn, activation_type):  return getattr(nn, activation_type)()\n",
        "    else:  return nn.ReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_to-nG9VHau"
      },
      "source": [
        ">Complétez la classe `ConvBatchNorm`. Vous aurez besoin de:\n",
        ">- `get_activation`\n",
        ">- `BatchNorm2d`\n",
        ">- `Conv2d`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjI9ZLS1VHaw"
      },
      "source": [
        "class ConvBatchNorm(nn.Module):\n",
        "    \"\"\"This block implements the sequence: (convolution => [BN] => ReLU)\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, activation='ReLU'):\n",
        "        super(ConvBatchNorm, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size=3, padding=1)\n",
        "        self.norm = nn.BatchNorm2d( out_channels)\n",
        "        self.activation = get_activation(activation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_conv = self.conv(x)\n",
        "        out_norm = self.norm(out_conv)\n",
        "        out_activation = self.activation(out_norm)\n",
        "        return out_activation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_conv = ConvBatchNorm(1, 64)\n",
        "\n",
        "x = torch.rand(4, 1, 96, 96)\n",
        "y = test_conv(x)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "er0wWpbUR16Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCygJq5VHay"
      },
      "source": [
        "Que fait la fonction `_make_nConv` ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_lwX9LuVHaz"
      },
      "source": [
        "def _make_nConv(in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "    layers = []\n",
        "    layers.append(ConvBatchNorm(in_channels, out_channels, activation))\n",
        "    for _ in range(nb_Conv-1):\n",
        "        layers.append(ConvBatchNorm(out_channels, out_channels, activation))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_cz-28VHa0"
      },
      "source": [
        ">Complétez les classes:\n",
        ">- `ConvBatchNorm`\n",
        ">- `DownConvBlock`: cette classe sera utilisée pour construire la partie **encoder**  du UNet.\n",
        ">- `UpConvBlock`: cette classe sera utilisée pour construire la partie **decoder** du UNet.\n",
        "\n",
        ">Vous aurez besoin des couches Pytorch suivantes:\n",
        ">- `MaxPool2d`,\n",
        ">- `ConvTransposed2d` ou `Upsample`,\n",
        ">- `ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQJbRxlfZmAb"
      },
      "source": [
        "class DownBlock(nn.Module):\n",
        "    \"\"\"Downscaling with maxpooling and convolutions\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "        super(DownBlock, self).__init__()\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_maxpool = self.maxpool(x)\n",
        "        out_nconvs = self.nConvs(out_maxpool)\n",
        "        return out_nconvs\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2, activation='ReLU'):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.nConvs(input)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    \"\"\"Upscaling then conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2, activation='ReLU'):\n",
        "        super(UpBlock, self).__init__()\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2)\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "    def forward(self, x, skip_x):\n",
        "\n",
        "        out_up = self.up(x)\n",
        "\n",
        "        # Skip connection (use torch.cat function)\n",
        "        x = torch.cat([out_up, skip_x], dim=1)\n",
        "        return self.nConvs(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_down = DownBlock(64, 128, nb_Conv=2)\n",
        "x = torch.rand(4, 64, 96, 96)\n",
        "y = test_down(x)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "test_down = Bottleneck(512, 512, nb_Conv=2)\n",
        "x = torch.rand(4, 512, 96, 96)\n",
        "y = test_down(x)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "test_down = UpBlock(512, 512, nb_Conv=2)\n",
        "x_1 = torch.rand(4, 256, 96, 96)\n",
        "x_skip = torch.rand(4, 256, 192, 192)\n",
        "\n",
        "y = test_down(x_1, x_skip)\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "gi-HtoNlUlwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK4PhCrQVHa3"
      },
      "source": [
        "### **ii. UNet architecture**\n",
        "\n",
        "Ici vous utiliserez les building blocks codés précédemment pour construire l'architecture complète du UNet.\n",
        "\n",
        "- Soyez vigilant aux nombres de canaux d'entrée et de sortie de chaque bloc lorsque vous implémentez les skip connections.\n",
        "\n",
        "- Comparez le code suivant avec la figure du UNet. Où sont les `DownConvBlock`, les `UpConvBlock` ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi_jPXtGZ1-p"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=4, n_classes=4):\n",
        "        '''\n",
        "        n_channels : number of channels of the input.\n",
        "                        By default 4, because we have 4 modalities\n",
        "        n_labels : number of channels of the ouput.\n",
        "                      By default 4 (3 labels + 1 for the background)\n",
        "        '''\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Question here\n",
        "\n",
        "        self.inc = ConvBatchNorm(n_channels, 64)\n",
        "        self.down1 = DownBlock(64, 128, nb_Conv=2)\n",
        "        self.down2 = DownBlock(128, 256, nb_Conv=2)\n",
        "        self.down3 = DownBlock(256, 512, nb_Conv=2)\n",
        "        self.down4 = DownBlock(512, 512, nb_Conv=2)\n",
        "\n",
        "        self.Encoder = [self.down1, self.down2, self.down3, self.down4]\n",
        "\n",
        "        self.bottleneck = Bottleneck(512, 512)\n",
        "\n",
        "        self.up1 = UpBlock(1024, 256, nb_Conv=2)\n",
        "        self.up2 = UpBlock(512, 128, nb_Conv=2)\n",
        "        self.up3 = UpBlock(256, 64, nb_Conv=2)\n",
        "\n",
        "        self.Decoder = [self.up1, self.up2, self.up3]\n",
        "\n",
        "        self.outc = nn.Sequential(nn.ConvTranspose2d(64, 64,\n",
        "                                                     kernel_size=3, stride=2,\n",
        "                                                     padding=1, output_padding=1),\n",
        "                                  nn.Conv2d(64, self.n_classes, kernel_size=3, stride=1, padding=1)\n",
        "                                  )\n",
        "        self.last_activation = get_activation('Softmax')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward\n",
        "        skip_inputs = []\n",
        "        x = self.inc(x)\n",
        "\n",
        "        # Forward through encoder\n",
        "        for i, block in enumerate(self.Encoder):\n",
        "\n",
        "            x = block(x)\n",
        "            skip_inputs += [x]\n",
        "            print(x.shape)\n",
        "\n",
        "        # We are at the bottleneck.\n",
        "        bottleneck = self.bottleneck(x)\n",
        "\n",
        "        # Forward through decoder\n",
        "        skip_inputs.reverse()\n",
        "\n",
        "        decoded = bottleneck\n",
        "        for i, block in enumerate(self.Decoder):\n",
        "\n",
        "            # Concat with skipconnections\n",
        "            skipped = skip_inputs[i+1]\n",
        "            print(skipped.shape, decoded.shape)\n",
        "            decoded = block(decoded, skipped)\n",
        "\n",
        "        out = self.last_activation(self.outc(decoded))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unet = UNet()\n",
        "x = torch.rand(4, 4, 96, 96)\n",
        "y = test_unet(x)\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "B1w9PhDYbgFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtCpyZv8t8L"
      },
      "source": [
        "## 3.b. Analyse du modèle.\n",
        "\n",
        "> Pour étudier et débugger le modèle, vous pouvez lui donner en entrée un tensor random de taille `(1, 4, 96, 96)` (batch size, number of modalites, image shape) avec la fonction `torch.rand`.\n",
        "\n",
        "> La taille de la sortie du réseau doit être la même que celle de l'image d'entrée.\n",
        "\n",
        "> Pour mieux débugger, il vous faudra peut être modifier votre code pour affichier les tailles des sorties de chaque couche du réseau .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktk3C0AWapYk"
      },
      "source": [
        "model = UNet(n_channels=4, n_classes=4)\n",
        "print(model)\n",
        "\n",
        "# Image of size 96*96 with 4 modality + batch size = 1\n",
        "x = torch.rand(1, 4, 96, 96)\n",
        "y = model(x)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvYD-ZzAoll"
      },
      "source": [
        "# **4. Création du dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-E8AoHtV4PG"
      },
      "source": [
        "## 4.a. Fonctions utiles -  CODE A EXECUTER ET A CACHER\n",
        "\n",
        "\n",
        "Le code suivant est nécessaire pour entraîner correctement le modèle et est déjà codé.\n",
        "\n",
        "Exécutez la cellule suivante. Vous pouvez essayer de comprendre ce que chaque fonction fait."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1coYIDpScNmD"
      },
      "source": [
        "end = '.nii.gz'\n",
        "seg_name = '_seg'\n",
        "\n",
        "def load_split(split_folder):\n",
        "    '''\n",
        "        return train, val, test split with loadtxt\n",
        "    '''\n",
        "    train_split = np.loadtxt(os.path.join(\n",
        "        split_folder, 'train.txt'), dtype=str)\n",
        "    val_split = np.loadtxt(os.path.join(split_folder, 'val.txt'), dtype=str)\n",
        "    test_split = np.loadtxt(os.path.join(split_folder, 'test.txt'), dtype=str)\n",
        "    return train_split, val_split, test_split\n",
        "\n",
        "\n",
        "def load_sitk(path):\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
        "\n",
        "\n",
        "def find_z_slice(list_patient, threshold, dataframe):\n",
        "    \"\"\"\n",
        "    For each patient in list_patient, this function returns the list of slices where\n",
        "    the corresponding image is not empty\"\"\"\n",
        "\n",
        "    list_IDs = []\n",
        "    for patient in list_patient:\n",
        "        if threshold > 0:\n",
        "            condition = dataframe[patient].values >= threshold\n",
        "            z_slice = np.where(condition)[0]\n",
        "        else:\n",
        "            z_slice = range(155)\n",
        "        list_IDs += list(set([(patient, int(z//2)) for z in z_slice]))\n",
        "\n",
        "    return list_IDs\n",
        "\n",
        "\n",
        "def generate_IDs(train_split, val_split, test_split,\n",
        "                 tumor_percentage, csv_path, image_size=(240, 240)):\n",
        "\n",
        "    tumor_volume_dataframe = pd.read_csv(csv_path)\n",
        "    threshold = int(tumor_percentage * np.prod(image_size) / 100)\n",
        "\n",
        "    train_IDs, val_IDs, test_IDs = [], [], []\n",
        "    train_IDs = find_z_slice(train_split, threshold, tumor_volume_dataframe)\n",
        "    val_IDs = find_z_slice(val_split, threshold, tumor_volume_dataframe)\n",
        "    test_IDs = find_z_slice(test_split, 0, tumor_volume_dataframe)\n",
        "    return train_IDs, val_IDs, test_IDs\n",
        "\n",
        "\n",
        "def to_var(x, device):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x)\n",
        "    x = x.to(device)\n",
        "    return x\n",
        "\n",
        "def to_numpy(x):\n",
        "    if not (isinstance(x, np.ndarray) or x is None):\n",
        "        if x.is_cuda:\n",
        "            x = x.data.cpu()\n",
        "        x = x.numpy()\n",
        "    return x\n",
        "\n",
        "def save_checkpoint(state, save_path):\n",
        "    '''\n",
        "        Save the current model.\n",
        "        If the model is the best model since beginning of the training\n",
        "        it will be copy\n",
        "    '''\n",
        "\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    epoch = state['epoch']\n",
        "    val_loss = state['val_loss']\n",
        "    filename = save_path + '/' + \\\n",
        "        'model.{:02d}--{:.3f}.pth.tar'.format(epoch, val_loss)\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def print_summary(epoch, i, nb_batch, loss, batch_time,\n",
        "                  average_loss, average_time, mode):\n",
        "    '''\n",
        "        mode = Train or Test\n",
        "    '''\n",
        "    summary = '[' + str(mode) + '] Epoch: [{0}][{1}/{2}]\\t'.format(\n",
        "        epoch, i, nb_batch)\n",
        "\n",
        "    string = ''\n",
        "    string += ('Dice Loss {:.4f} ').format(loss)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_loss)\n",
        "    string += ('Batch Time {:.4f} ').format(batch_time)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_time)\n",
        "\n",
        "    summary += string\n",
        "    print(summary)\n",
        "\n",
        "def plot(irms, masks=None, pred_masks=None):\n",
        "\n",
        "    kwargs = {'cmap': 'gray'}\n",
        "    fig, ax = plt.subplots(2, 3, gridspec_kw={'wspace': 0.15, 'hspace': 0.2,\n",
        "                                              'top': 0.85, 'bottom': 0.1,\n",
        "                                              'left': 0.05, 'right': 0.95},\n",
        "                           figsize=(12, 7))\n",
        "    ax[0, 0].imshow(irms[0, :, :], **kwargs)\n",
        "\n",
        "    if masks is not None:\n",
        "        masks = np.argmax(masks, axis=0)\n",
        "        ax[0, 1].imshow(masks, vmin=0, vmax=3)\n",
        "\n",
        "    if pred_masks is not None:\n",
        "        pred_masks = np.argmax(pred_masks, axis=0)\n",
        "        ax[0, 2].imshow(pred_masks, vmin=0, vmax=3)\n",
        "\n",
        "    for i in range(3):\n",
        "        ax[1, i].imshow(irms[i+1, :, :], **kwargs)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i, j].grid(False)\n",
        "            ax[i, j].axis('off')\n",
        "            ax[i, j].set_xticks([])\n",
        "            ax[i, j].set_yticks([])\n",
        "\n",
        "    ax[0, 0].set_title('IRM T1')\n",
        "    ax[1, 0].set_title('IRM Gado')\n",
        "    ax[1, 1].set_title('IRM T2')\n",
        "    ax[1, 2].set_title('IRM Flair')\n",
        "    ax[0, 1].set_title('Ground Truth Seg')\n",
        "    ax[0, 2].set_title('Predicted Seg')\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    return fig\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ehHeKmVHbD"
      },
      "source": [
        "## 4.b. Classe `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GREf0GN5VHbE"
      },
      "source": [
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    'Generates data for torch'\n",
        "\n",
        "    def __init__(self, files_list, data_path, modalities=['t1', 't2', 't1ce', 'flair'], transform=None):\n",
        "        super(SegmentationDataset, self).__init__()\n",
        "        self.files_list = files_list\n",
        "        self.transform = transform\n",
        "        self.data_path = data_path\n",
        "        self.modalities = modalities\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Get a patient given idx'\n",
        "        patient = self.files_list[idx]\n",
        "\n",
        "        # Load the patient's modalities and segmentation masks\n",
        "        irm, mask = self.load(patient)\n",
        "        sample = (irm, mask)\n",
        "\n",
        "        # Apply data transformation\n",
        "        if self.transform:\n",
        "            irm, mask = self.transform(sample)\n",
        "        return (irm, mask, patient)\n",
        "\n",
        "    def load(self, ID):\n",
        "\n",
        "        patient, z_slice = ID\n",
        "        patient_path = os.path.join(self.data_path, patient)\n",
        "\n",
        "        # Get all modalities for the given slice\n",
        "        irm = []\n",
        "        for modality in self.modalities:\n",
        "            file_name = \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice)\n",
        "            path = os.path.join(patient_path, file_name)\n",
        "            irm.append(load_sitk(path))\n",
        "        irm = np.stack(irm, axis=0)\n",
        "\n",
        "        # Get the segmentation mask for the given slice\n",
        "        seg_name = \"{patient}_seg_z_{z_slice}.nii.gz\".format(patient=patient, z_slice=z_slice)\n",
        "        mask_path = os.path.join(patient_path, seg_name)\n",
        "        mask = load_sitk(mask_path)\n",
        "        mask[mask == 4] = 3\n",
        "\n",
        "        # Convert segmentation mask to one-hot encoding\n",
        "        label = 4\n",
        "        mask = mask.astype(np.int16)\n",
        "        mask = np.rollaxis(np.eye(label, dtype=np.uint8)[mask], -1, 0)\n",
        "        return irm, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28f8xpE8VHbG"
      },
      "source": [
        "## 4.c. Génération des différents datasets et des listes de coupes pour chaque patient.\n",
        "\n",
        "`train_IDs`, `val_IDs` et `test_IDs` sont des variables qui correspondent à la variable `files_list` nécessaire lors de la création d'instance de la classe `SegmentationDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIlHj1mhVHbG"
      },
      "source": [
        "# Load the split, generate the IDs list\n",
        "datasets_path ='./GEP1/datasets/'\n",
        "csv_path = './GEP1/data/tumor_count.csv'\n",
        "\n",
        "# The tumour percentage is the percentage of tumour in an image. It's a threshold\n",
        "# that is used when selecting relevant slice indexes in a patient's images.\n",
        "tumour_percentage = 0.5\n",
        "train_split, val_split, test_split = load_split(datasets_path)\n",
        "\n",
        "(train_IDs, val_IDs, test_IDs) = generate_IDs(train_split, val_split, test_split, tumour_percentage, csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug7XxwsMVHbH"
      },
      "source": [
        "val_IDs[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3x2uH6IVHbJ"
      },
      "source": [
        "## 4.d. Creation des instances de la classe `SegmentationDataset` pour chaque dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLUqBzZ20vJH"
      },
      "source": [
        "# No data augmentation implemented yet.\n",
        "transformation=None\n",
        "\n",
        "train_Dataset = SegmentationDataset(train_IDs, data_path=data_path, transform=transformation)\n",
        "\n",
        "val_Dataset = \"\"\"Complete here\"\"\"\n",
        "\n",
        "test_Dataset = \"\"\"Complete here\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eXLezjAVHbK"
      },
      "source": [
        "The following cell calls for a sample of the training set. Running `train_Dataset[0]` actually calls the `__getitem__` method of the `SegmentationDataset` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvXjeUK4VHbL"
      },
      "source": [
        "input_modalities, segmentation_mask, patient = train_Dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLHlL7QvVHbM"
      },
      "source": [
        "print(\"Shape of the input:\", input_modalities.shape)\n",
        "print(\"Shape of the segmentation masks:\", segmentation_mask.shape)\n",
        "print(\"Patient identification:\", patient[0])\n",
        "print(\"Selected slice:\", patient[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivb7gvj9VHbO"
      },
      "source": [
        "## 4.e. Création des `DataLoader` utilisés pour l'entraînement.\n",
        "\n",
        "Pour chaque dataset split (train, validation, test), vous devez spécifier:\n",
        "- la taille du batch avec la variable `batch_size`.\n",
        "- s'il faut mélanger le dataset pour donner des batch random de données au modèle avec la varibale `shuffle`.\n",
        "- s'il faut ignorer le dernier batch incomplet, dans le cas où la taille du dataset n'est pas divisible par la taille de batch choisie, avec la variable `drop_last`. Cette variable est particulièrement utile lorsqu'on utilise du multiprocessing (`num_workers` > 1) dans le `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhN9-SfVHbQ"
      },
      "source": [
        "# Define the batch size\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_Dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "val_loader = \"\"\"Complete here\"\"\"\n",
        "\n",
        "test_loader = \"\"\"Complete here\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y-dKzlyVHbR"
      },
      "source": [
        "# **5. Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbL3St5dVHbT"
      },
      "source": [
        "## 5.a. Loss function, optimizer et hyperparamètres\n",
        "\n",
        "Ici, il vous faudra choisir:\n",
        "- la fonction de perte utilisée pour optimiser les paramètres du modèle(voir [ici](https://pytorch.org/docs/stable/nn.html#loss-functions)),\n",
        "- l'optimizer (voir [ici](https://pytorch.org/docs/stable/optim.html))\n",
        "- tous les hyperparamètres correspondant: learning rate, weight decay ...\n",
        "\n",
        "\n",
        ">Pour commencer, vous pouvez:\n",
        ">- Choisir `Adam` comme optimizer\n",
        ">- Coder votre propre fonction de coût comme étant la Dice loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXuDCj_bJuu_"
      },
      "source": [
        "def dice_loss(input, target):\n",
        "    smooth = 1.\n",
        "    target = target.float()\n",
        "    input = input.float()\n",
        "    input_flat = input.contiguous().view(-1)\n",
        "    target_flat = target.contiguous().view(-1)\n",
        "    intersection = (input_flat * target_flat).sum()\n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "                (input_flat.pow(2).sum() + target_flat.pow(2).sum() + smooth))\n",
        "\n",
        "def mean_dice_loss(input, target):\n",
        "    channels = list(range(target.shape[1]))\n",
        "    loss = 0\n",
        "    for channel in channels:\n",
        "        dice = dice_loss(input[:, channel, ...],\n",
        "                         target[:, channel, ...])\n",
        "        loss += dice\n",
        "    return loss / len(channels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3T1rsaWVHbW"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "criterion = mean_dice_loss # Choose loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Choose optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccumlRADVHbX"
      },
      "source": [
        "## 5.b. Le modèle\n",
        "\n",
        "Pour créer une instance de la classe `UNet`, vous devez spécifier:\n",
        "- le nombre de canaux d'entrée `n_channels` qui devrait être égal au nombre de modalités considérées (soit 4 modalités)\n",
        "- le nombre de classes de segmentation `n_classes` = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUoS5wUQVHbY"
      },
      "source": [
        "n_modalities = 4\n",
        "n_classes = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "o2_ojZwTVHbY"
      },
      "source": [
        "# torch.cuda.set_device(3)\n",
        "\n",
        "model = UNet()# Create model\n",
        "model.cuda() # move model to GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzLyZKWVHbZ"
      },
      "source": [
        "## 5.c. Training loop pour une seule époque\n",
        "\n",
        "\n",
        "Ici, vous devez compléter la fonciton `train_loop`, qui parcours tout le dataset `loader` une seule fois.\n",
        "\n",
        "Quand le modèle est en entraînement, soit `model.training == True`, il est nécessaire que cette fonction performe aussi la rétropropagation et la mise-à-jour des paramètres du modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AHqde7wdTkM"
      },
      "source": [
        "# Train the model\n",
        "def train_loop(loader, model, criterion, optimizer, writer, epoch):\n",
        "\n",
        "    logging_mode = 'Train' if model.training else 'Val'\n",
        "\n",
        "\n",
        "    epoch_time_sum, epoch_loss_sum = [], []\n",
        "\n",
        "    for i, sample in enumerate(loader, 1):\n",
        "        start = time.time()\n",
        "        # Take variable\n",
        "        (irms, masks, patients) = sample\n",
        "        # print(irms.shape) # Batch * Number of Modalities * Width * Height\n",
        "\n",
        "        # Put variables to GPU\n",
        "        irms = irms.float().cuda()\n",
        "        masks = masks.float().cuda()\n",
        "\n",
        "        # compute model prediction\n",
        "        pred_masks = model(irms)\n",
        "\n",
        "        # compute loss\n",
        "        dice_loss = criterion(pred_masks, masks)\n",
        "\n",
        "        # If in training mode ...\n",
        "        if model.training:\n",
        "            # Initialize optimizer gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            # Perform backpropagation\n",
        "            dice_loss.backward()\n",
        "            # Update the model's trainable parameters using the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "        # Compute elapsed time\n",
        "        batch_time = time.time() - start\n",
        "\n",
        "        epoch_time_sum += [batch_time]\n",
        "        epoch_loss_sum += [dice_loss.item()]\n",
        "\n",
        "        average_time = np.mean(epoch_time_sum)\n",
        "        average_loss = np.mean(epoch_loss_sum)\n",
        "\n",
        "        if i % print_frequency == 0:\n",
        "            print_summary(epoch + 1, i, len(loader), dice_loss, batch_time,\n",
        "                          average_loss, average_time, logging_mode)\n",
        "        step = epoch*len(loader) + i\n",
        "        writer.add_scalar(logging_mode + '_dice', dice_loss.item(),step)\n",
        "\n",
        "\n",
        "\n",
        "    writer.add_scalar(logging_mode + '_global_loss', np.mean(epoch_loss_sum), epoch)\n",
        "\n",
        "\n",
        "    # Save some figures to monitor segmentation quality\n",
        "    n_modalities = irms.shape[0]\n",
        "    irms = to_numpy(irms)\n",
        "    masks = to_numpy(masks)\n",
        "    pred_masks = to_numpy(pred_masks)\n",
        "\n",
        "    for batch in range(n_modalities):\n",
        "        fig = plot(irms[batch, ...], masks[batch, ...], pred_masks[batch, ...])\n",
        "        writer.add_figure(logging_mode + str(batch), fig, epoch)\n",
        "    writer.flush()\n",
        "    return np.mean(epoch_loss_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPelDIO4VHbb"
      },
      "source": [
        "## 5.d. Entraînez votre modèle\n",
        " Vous utiliserez **Tensorboard** afin de surveiller que la fonction de loss diminue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIfIBakVHbc"
      },
      "source": [
        "save_path = \"./GEP1/save/\"\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "model_path = save_path + 'models/' + session_name + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-umPqFHnVHbe"
      },
      "source": [
        "# Start tensorboard\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "tensorboard_folder = save_path + 'tensorboard_logs/'\n",
        "log_dir = tensorboard_folder + session_name + '/'\n",
        "\n",
        "if not os.path.isdir(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "writer = torch.utils.tensorboard.SummaryWriter(log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8q7mWgOcwnb"
      },
      "source": [
        "epochs = 5\n",
        "print_frequency = 10\n",
        "save_frequency = 10\n",
        "save_model = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxyPwfvYw5d5"
      },
      "source": [
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "    print(session_name)\n",
        "\n",
        "    # train for one epoch\n",
        "    model.train()\n",
        "    print('Training')\n",
        "\n",
        "    train_loss = train_loop(train_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    print('Validation')\n",
        "    with torch.no_grad():   # Disable gradient computation (faster and saves memory)\n",
        "        model.eval()        # Disable Dropout and BatchNormalization\n",
        "\n",
        "        val_loss = train_loop(val_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    if save_model and epoch % save_frequency == 0:\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                         'val_loss': val_loss,\n",
        "                         'optimizer': optimizer.state_dict()}, model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5A4lVLHVHbg"
      },
      "source": [
        "#### Look at tensorboard to see the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if7Rn5i9VHbh"
      },
      "source": [
        "!tensorboard --logdir=./GEP1/save/tensorboard_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir './GEP1/save/tensorboard_logs/'\n",
        "\n",
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances\n",
        "notebook.display(port=6006, height=1000)"
      ],
      "metadata": {
        "id": "jqzFo-UD-gYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2kqcqsLqIQm"
      },
      "source": [
        "# **6. Prediction et Evaluation**\n",
        "\n",
        "\n",
        "Après avoir entraîné votre modèle, nous devons maintenant:\n",
        "\n",
        "1.  Utiliser le modèle pour prédire une segmentation.\n",
        "\n",
        "2.  Evaluer les performances du modèles sur le test set.\n",
        "\n",
        "L'évaluation du modèle doit être faite sur le test set, qui n'a pas été vu pendant le training. Le validation set n'était utile que pour contrôler les éventuels problèmes d'overfitting / underfitting.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTIU3BrlhsY"
      },
      "source": [
        "## 6.a. Prediction et retour à l'espace d'origine\n",
        "\n",
        "Dans cet exercice:\n",
        ">- Nous allons charger le modèle pré-entraîné et utiliser la fonction `predict()` pour prédire une segmentation.\n",
        ">- La segmentation prédite aura pour taille `(96, 96, 4)`, pour une coupe selon l'axe Z.\n",
        ">- Afin de faire la comparaison avec les data d'origine, il est nécessaire de retransformer la prédiction en un volume de taille `(155, 240, 240)`.\n",
        "\n",
        "Afin de faire cela, il faudra:\n",
        "\n",
        "- Appliquer la fonction `predict()` à un dataloader. Dans cette étape d'évaluation, il n'y a pas besoin de faire de rétropropagation ni de mettre à jour les paramètres du modèle.\n",
        "- Appliquer la fonction `reconstruct_patient()` afin de reconstruire un volume entier pour un patient donné.\n",
        "- Appliquer la fonction  `get_mask2original_shape()` à la prédiction pour passer d'une taille `(78, 4, 96, 96)` à `(155, 240, 240)`\n",
        "\n",
        "**Questions**\n",
        "- Complétez la fonction `predict()`\n",
        "- Etudiez la fonction `get_mask2original_shape()`. Que font les différentes fonctions internes ? Essayez de deviner les tailles de chaque variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhq4Eat0oJZ1"
      },
      "source": [
        "def predict(loader, model, batch_size=1):\n",
        "    preds = {}\n",
        "    for i, sample in tqdm(enumerate(loader, 1)):\n",
        "        # Take variable and put them to GPU\n",
        "        (irms, masks, patients) = sample\n",
        "\n",
        "        irms = \"\"\"Complete here\"\"\"\n",
        "        masks = \"\"\"Complete here\"\"\"\n",
        "\n",
        "        batch_patient_names, batch_z_slices = patients[0], patients[1]\n",
        "\n",
        "        # compute output\n",
        "        pred_masks = predict(test_loader)\n",
        "\n",
        "        # Put the predictions in a dictionnary with one key being the\n",
        "        # patient and the z slice\n",
        "        n_batch = len(pred_masks)\n",
        "        for j in range(n_batch):\n",
        "            patient, z_slice = batch_patient_names[j], batch_z_slices[j]\n",
        "            name = patient + '_z_' + str(to_numpy(z_slice))\n",
        "            preds[name] = to_numpy(pred_masks[j])\n",
        "    return preds\n",
        "\n",
        "def reconstruct_patient(preds, patient, z_max = 78):\n",
        "    '''\n",
        "    From the dictionnary with prediction find the slice corresponding to\n",
        "    one patient and construct a 3D matrix of shape 77*96*96\n",
        "    '''\n",
        "    X = []\n",
        "    for i in range(z_max):\n",
        "        name = patient + '_z_' + str(i)\n",
        "        array_slice = preds[name]\n",
        "        X.append(array_slice)\n",
        "    X = np.stack(X, axis=0)\n",
        "    return X\n",
        "\n",
        "\n",
        "def get_mask2original_shape(predict_mask):\n",
        "    mask = np.zeros(shape=(155,240, 240))\n",
        "    res = skimage.transform.resize(predict_mask, (155, 4, 192, 192))\n",
        "    res = res > 0.5\n",
        "    res = np.argmax(res, axis=1)\n",
        "    mask[:, 24:-24, 24:-24] = res\n",
        "    mask[mask == 3] = 4\n",
        "    return mask.astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ac8F9PsJgG"
      },
      "source": [
        "test_path = original_data_path\n",
        "patients = [os.path.basename(p) for p in glob(test_path + \"*\")]\n",
        "patient = patients[0]\n",
        "\n",
        "model.eval()\n",
        "# Make prediction\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model)\n",
        "\n",
        "# reconstruct the patient's complete volume\n",
        "predict_mask = reconstruct_patient(preds, patient)\n",
        "\n",
        "for i in range(len(predict_mask)):\n",
        "    plt.figure()\n",
        "    plt.title(\"Model prediction - slice {}/{}\".format(i+1, len(predict_mask)+1))\n",
        "    plt.imshow(np.argmax(predict_mask[i, ...], axis=0))\n",
        "    plt.show()\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(\"Mask shape:\", predict_mask.shape)\n",
        "\n",
        "# Return to original shape\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n",
        "\n",
        "\n",
        "print(\"Resized mask shape:\", predict_mask.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjT3WF0el3yb"
      },
      "source": [
        "## 6.b. Comparaison visuelle\n",
        "\n",
        "\n",
        "Nous allons faire une comparaison qualitative entre la segmentation prédite par le modèle et la segmentation de référence.\n",
        "\n",
        "\n",
        "**Questions**\n",
        "- Chargez la segmentation de référence (dans le dossier `/GEP1/origin_data`) et, en utilisant les fonctions `plt.subplot`, `plt.imshow` et `plt.title`, affichez le masque de segmentation prédit par le modèle, et la segmentation de référence côte à côte.\n",
        "\n",
        "- Etudiez la fonction `numpy2nifti`. Que fait-elle ? Appliquez-là et sauvegardez les masques de segmentation prédits sous format nifti `.nii`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKSDSeAkaBmC"
      },
      "source": [
        "# Compare visual plot of prediction and original mask\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "patient_folder = os.path.join(test_path, patient)\n",
        "orig_image = sitk.ReadImage(os.path.join(patient_folder, patient  + '_seg.nii.gz' ))\n",
        "orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "z_slice=100\n",
        "for z_slice in range(orig_mask.shape[0]):\n",
        "    plt.figure(figsize=(13, 6))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(orig_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "    plt.title('Original mask (slice {})'.format(z_slice))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(predict_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "    plt.title('Predicted mask (slice {})'.format(z_slice))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A3-sCKcDtp0"
      },
      "source": [
        "def numpy2sitk(predict_mask, orig_img):\n",
        "    '''\n",
        "    Input : predict_mask of type numpy array\n",
        "            orig_img of type SimpleITK image\n",
        "    Output : new_img of type SimpleITK image\n",
        "    '''\n",
        "    new_img = sitk.GetImageFromArray(predict_mask)\n",
        "    new_img.SetDirection(orig_img.GetDirection())\n",
        "    new_img.SetOrigin(orig_img.GetOrigin())\n",
        "    new_img.SetSpacing(orig_img.GetSpacing())\n",
        "    return new_img\n",
        "\n",
        "predict_img = numpy2sitk(predict_mask, orig_image)\n",
        "path = os.path.join(patient_folder, patient + '_predict_seg.nii.gz')\n",
        "sitk.WriteImage(predict_img, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saALPYgDmFzt"
      },
      "source": [
        "## 6.c. Metrics\n",
        "\n",
        "\n",
        "Nous allons maintenant calculer les métriques d'évaluation pour valider la performance du modèle.\n",
        "\n",
        "Nous allons utiliser 3 métriques:\n",
        "- la sensitivité (aussi appelée le taux de vrais positifs),\n",
        "- la spécificité (aussi appelée le taux de vrais négatifs),\n",
        "- le Dice score (qui est modifier lorsqu'il s'agit de la loss pendant l'entraînement en 1 - Dice score).\n",
        "\n",
        "Nous allons évaluer le modèle selon ces métriques en considérant les 5 patients du dossier `/GEP1/origin_data`. Dans les applications réelles, nous devrions évaluer les métriques sur les patients du test set.\n",
        "\n",
        "**Questions :**\n",
        "- Complétez la fonction `metrics()` afin de calculer le Dice, la sensitivité et la spécificité.\n",
        "- En utilisant les arrays `predict_mask` and `orig_mask` précédents, calculez les métriques. Vous avez juste à appliquer la fonction `evalAllSample()`. Affichez le résultat.\n",
        "- En utilisant une boucle `for`et toutes les fonctions définies dans la partie 3 du TP, calculez les métriques pour les patients du dossier `/GEP1/origin_data`. Affichez les valeurs moyennes de Dice pour chaque catégorie (WT, ET, TC).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebE_L5HE-LXv"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def metrics(mask_, gt_):\n",
        "    '''\n",
        "    Taking to binary array of same shape as input\n",
        "    This function compute the confusion matrix and use it to calculate\n",
        "    Dice metrics, Sensitivity and Specificity\n",
        "    Input : mask_, gt_ numpy array of identic shape (only 1 and 0)\n",
        "    Output : List of 3 scores\n",
        "    '''\n",
        "    lnot = np.logical_not\n",
        "    land = np.logical_and\n",
        "\n",
        "    true_positive = np.sum(land((mask_), (gt_)))\n",
        "    false_positive = np.sum(land((mask_), lnot(gt_)))\n",
        "    false_negative = np.sum(land(lnot(mask_), (gt_)))\n",
        "    true_negative = np.sum(land(lnot(mask_), lnot(gt_)))\n",
        "\n",
        "    M = np.array([[true_negative, false_negative],\n",
        "                [false_positive, true_positive]]).astype(np.float64)\n",
        "    metrics = {}\n",
        "    metrics['Sensitivity'] = \"\"\"Complete here\"\"\"\n",
        "    metrics['Specificity'] = \"\"\"Complete here\"\"\"\n",
        "    metrics['Dice'] =  \"\"\"Complete here\"\"\"\n",
        "\n",
        "\n",
        "    # metrics may be NaN if denominator is zero! use np.nanmean() while\n",
        "    # computing average to ignore NaNs.\n",
        "\n",
        "    return [metrics['Dice'], metrics['Sensitivity'], metrics['Specificity']]\n",
        "\n",
        "\n",
        "def evalAllSample(mask_, gt_):\n",
        "    '''\n",
        "    This functions takes as input two numpy arrays with labels between\n",
        "    0, 1, 2 and 4 and calculate the metrics as defined in BraTS data challenge\n",
        "    mask_ and gt_ should be array of int\n",
        "    '''\n",
        "    # whole tumor (labels 1,2,4)\n",
        "    mask_wt, gt_wt = (np.array([0, 1, 1, 0, 1])[mask_],\n",
        "                    np.array([0, 1, 1, 0, 1])[gt_])\n",
        "    wt_metrics = metrics(mask_wt, gt_wt)\n",
        "\n",
        "    # tumor core (labels 1,4)\n",
        "    mask_tc, gt_tc = (np.array([0, 1, 0, 0, 1])[mask_],\n",
        "                    np.array([0, 1, 0, 0, 1])[gt_])\n",
        "    tc_metrics = metrics(mask_tc, gt_tc)\n",
        "\n",
        "    # enhancing tumor (label 4)\n",
        "    mask_et, gt_et = (np.array([0, 0, 0, 0, 1])[mask_],\n",
        "                    np.array([0, 0, 0, 0, 1])[gt_])\n",
        "    et_metrics = metrics(mask_et, gt_et)\n",
        "\n",
        "    return pd.DataFrame({'wt': wt_metrics, 'tc': tc_metrics, 'et': et_metrics},\n",
        "                      index=['Dice', 'Sensitivity', 'Specificity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLCmi1oC-t8u"
      },
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model, batch_size=batch_size)\n",
        "\n",
        "for patient in patients:\n",
        "    # Path to original image\n",
        "    patient_folder = os.path.join(test_path,patient)\n",
        "    # Open image\n",
        "    orig_image = sitk.ReadImage(os.path.join(patient_folder,\n",
        "                                            patient  + '_seg.nii.gz'))\n",
        "    # Convert image to numpy array\n",
        "    orig_mask = \"\"\"Complete here\"\"\"\n",
        "\n",
        "    # Reconstruct the whole patient predicted mask\n",
        "    predict_mask = \"\"\"Complete here\"\"\"\n",
        "    predict_mask = \"\"\"Complete here\"\"\"\n",
        "\n",
        "    print('*********** {} ***********'.format(patient))\n",
        "    # Use the evalAllSamples function to evaluate model\n",
        "    scores = \"\"\"Complete here\"\"\"\n",
        "    print(scores)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "    et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "    tc_dice_list.append(scores.loc['Dice', 'tc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlCr9vpxO1-u"
      },
      "source": [
        "print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n",
        "print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KV5wjPZ_lo7"
      },
      "source": [
        "# **7. Data Augmentation**\n",
        " Dans cette partie, nous allons utiliser des techniques de data augmentation afin d'améliorer les performances du modèle. Parce que les réseaux de neurones convolutifs sont invariants par translation uniquement, l'idée est de créer des échantillons artificiels à partir des données du training set pour que le modèle \"voie\" plus de données et apprenne à mieux généraliser et donc à affiner ses prédictions\n",
        " .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3opEW1YgEGOw"
      },
      "source": [
        "import scipy\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "\n",
        "class AxialFlip(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        choice_x = np.random.randint(0, 2)\n",
        "        choice_y = np.random.randint(0, 2)\n",
        "        irm, mask = sample\n",
        "        new_sample = (self.axialflip(irm, choice_x, choice_y),\n",
        "                      self.axialflip(mask, choice_x, choice_y))\n",
        "        return new_sample\n",
        "\n",
        "    def axialflip(self, array, choice_x, choice_y):\n",
        "        if choice_x == 1:  array = array[:, ::-1, :]\n",
        "        if choice_y == 1:  array = array[:, ::-1, ::-1]\n",
        "        return np.ascontiguousarray(array)\n",
        "\n",
        "class RandomRotation90(object):\n",
        "    '''\n",
        "        Taken from augment_rot90 from MIC-DKFZ/batchgenerators\n",
        "        https://github.com/MIC-DKFZ/batchgenerators/blob/master/batchgenerators/augmentations/spatial_transformations.py\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_rot=(1, 2, 3, 4)):\n",
        "        self.num_rot = num_rot\n",
        "        self.axes = (1,2)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        '''\n",
        "          irm and mask have shape (Modality*Width*Height) and (Label*Width*Height)\n",
        "        '''\n",
        "        num_rot = np.random.choice(self.num_rot)\n",
        "        def f(img):\n",
        "            return np.ascontiguousarray(np.rot90(img, num_rot, self.axes))\n",
        "\n",
        "        irm, mask = sample\n",
        "        new_sample = (f(irm), f(mask))\n",
        "        return new_sample\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, cubic crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size, dim=2):\n",
        "        assert isinstance(output_size, (int, tuple, list))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = dim * (output_size,)\n",
        "        else:\n",
        "            assert len(output_size) == dim\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        irm, mask = sample\n",
        "        _, height, width = irm.shape\n",
        "        i = np.random.randint(0, height - self.output_size[0])\n",
        "        j = np.random.randint(0, width - self.output_size[1])\n",
        "\n",
        "        def f(img):\n",
        "            return img[:, i: i + self.output_size[0], j : j + self.output_size[1]]\n",
        "\n",
        "        new_sample = ( f(irm), f(mask))\n",
        "        return new_sample\n",
        "\n",
        "def RandomTranslation(max_translation=30, transform_matrix=None, debug=False):\n",
        "    translation = np.random.randint(-max_translation, max_translation, 2)\n",
        "    if debug:\n",
        "        return getTranslationMatrix(translation, transform_matrix), (translation)\n",
        "    else:\n",
        "        return getTranslationMatrix(translation, transform_matrix)\n",
        "\n",
        "def RandomRotation(theta_max=20, transform_matrix=None, debug=False):\n",
        "    theta = np.random.uniform(-theta_max, theta_max)\n",
        "    if debug:\n",
        "        return getRotationMatrix(theta, transform_matrix), theta\n",
        "    else:\n",
        "        return getRotationMatrix(theta, transform_matrix)\n",
        "\n",
        "def RandomZoom(zoom_max=0.2, transform_matrix=None, debug=False):\n",
        "    zoom = np.random.uniform(1 - zoom_max, 1 + zoom_max)\n",
        "    if debug:\n",
        "          return getZoomMatrix(zoom, transform_matrix), zoom\n",
        "    else:\n",
        "        return getZoomMatrix(zoom, transform_matrix)\n",
        "\n",
        "def getTranslationMatrix(translation, transform_matrix=None):\n",
        "    '''\n",
        "        2D translation on the axis (0, 1).\n",
        "        Axis 3 is the modality axis\n",
        "        tx: Width shift.\n",
        "        ty: Heigh shift.\n",
        "\n",
        "    '''\n",
        "    shift_matrix = np.array([[1, 0, translation[0]],\n",
        "                            [0, 1, translation[1]],\n",
        "                            [0, 0, 1]])\n",
        "\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = shift_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "def getZoomMatrix(zoom, transform_matrix=None):\n",
        "    '''\n",
        "        Affine Zoom in 2D\n",
        "        zx: Zoom in x direction.\n",
        "        zy: Zoom in y direction\n",
        "    '''\n",
        "    zoom_matrix = np.array([[zoom, 0, 0],\n",
        "                            [0, zoom, 0],\n",
        "                            [0, 0, 1]])\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = zoom_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "def getRotationMatrix(theta, transform_matrix=None):\n",
        "    '''\n",
        "        2D rotation on the axis (0, 1).\n",
        "        Axis 3 is the modality axis\n",
        "        theta: Rotation angle in degrees.\n",
        "    '''\n",
        "    theta = np.deg2rad(theta)\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "                                [np.sin(theta), np.cos(theta), 0],\n",
        "                                [0, 0, 1]])\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = rotation_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, rotation_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "\n",
        "def apply_affine_transform(x, seg=None, transform_matrix=None, crop_shape=None,\n",
        "                           fill_mode='nearest', cval=0., order=3):\n",
        "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
        "    # Arguments\n",
        "        x: 4D numpy array, single image, multimodalities (Modality*H*W)\n",
        "        fill_mode: Points outside the boundaries of the input\n",
        "            are filled according to the given mode\n",
        "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
        "        cval: Value used for points outside the boundaries\n",
        "            of the input if `mode='constant'`.\n",
        "        order: int, order of interpolation\n",
        "    # Returns\n",
        "        The transformed version of the input.\n",
        "    \"\"\"\n",
        "    if scipy is None:\n",
        "        raise ImportError('Image transformations require SciPy. '\n",
        "                          'Install SciPy.')\n",
        "    if transform_matrix is not None:\n",
        "        channels, h, w = x.shape\n",
        "        transform_matrix = transform_matrix_offset_center(transform_matrix,\n",
        "                                                          h, w)\n",
        "        res = [ scipy.ndimage.affine_transform(x[channel, ...], transform_matrix,\n",
        "                                              order=order, mode=fill_mode, cval=cval)  for channel in range(channels)]\n",
        "        x = np.stack(res, axis=0)\n",
        "\n",
        "        if seg is not None:\n",
        "            labels = seg.shape[0]\n",
        "            res = [scipy.ndimage.affine_transform(seg[label, ...], transform_matrix,\n",
        "                                                                order=order, mode=fill_mode, cval=cval) for label in range(labels)]\n",
        "            seg = np.stack(res, axis=0)\n",
        "            seg[seg > 0.5] = 1\n",
        "            seg[seg < 0.5] = 0\n",
        "            return x, seg\n",
        "    return x\n",
        "\n",
        "def transform_matrix_offset_center(matrix, x, y):\n",
        "    o_x = float(x) / 2 + 0.5\n",
        "    o_y = float(y) / 2 + 0.5\n",
        "    offset_matrix = np.array([[1, 0, o_x],\n",
        "                              [0, 1, o_y],\n",
        "                              [0, 0, 1]])\n",
        "    reset_matrix = np.array([[1, 0, -o_x],\n",
        "                             [0, 1, -o_y],\n",
        "                             [0, 0, 1]])\n",
        "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "class AffineTransform(object):\n",
        "\n",
        "    def __init__(self, theta=0, max_translation=0, max_zoom=0):\n",
        "        self.theta = theta\n",
        "        self.max_translation = max_translation\n",
        "        self.max_zoom = max_zoom\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        transform_matrix = np.eye(3)\n",
        "        if self.theta > 0:\n",
        "            transform_matrix = RandomRotation(self.theta)\n",
        "        if self.max_translation > 0:\n",
        "            transform_matrix = RandomTranslation(self.max_translation,\n",
        "                                                 transform_matrix)\n",
        "        if self.max_zoom > 0:\n",
        "            transform_matrix = RandomZoom(self.max_zoom,\n",
        "                                          transform_matrix)\n",
        "        new_irm, new_mask = apply_affine_transform(irm, mask, transform_matrix)\n",
        "        return (new_irm, new_mask)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zrwq0EFT-S"
      },
      "source": [
        "## 7.a. Etude de l'augmentation de données.\n",
        "\n",
        "Complétez le code suivant afin de visualiser les effets de différentes techniques d'augmentation de données implémentées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4S28vKJ_hXL"
      },
      "source": [
        "k = 3\n",
        "\n",
        "irms, masks, patient = next(iter(val_loader))\n",
        "\n",
        "# irms is a list of a numpy array of shape [Batch * W*H*Modality]\n",
        "irm = irms[0,:].numpy()\n",
        "mask = masks[0,:].numpy()\n",
        "\n",
        "fig = plot(irm, mask)\n",
        "fig.suptitle('Original image')\n",
        "fig.savefig(save_path + 'orig.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNKhDssJoJE"
      },
      "source": [
        "Axial Flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIcnxHDJnWQ"
      },
      "source": [
        "flip = \"\"\"Complete here\"\"\"\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = flip((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random Axial Flip')\n",
        "    fig.savefig(save_path + 'Axial_Flip{}.png'.format(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pb5eNdJ-sh"
      },
      "source": [
        "90° Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZV_gkMPKBoi"
      },
      "source": [
        "random90rotation = \"\"\"Complete here\"\"\"\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = random90rotation((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random 90 degrees Rotation')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72QMAGP7JTcw"
      },
      "source": [
        "randomcrop = RandomCrop((64, 64))\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = randomcrop((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random crop')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJsXnMv-Fgsh"
      },
      "source": [
        "Random Rotation with +/- 30°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSjJsOzdFaqc"
      },
      "source": [
        "rotate = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "\n",
        "\n",
        "    (new_irm, new_mask) = rotate((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random rotation')\n",
        "    fig.savefig(save_path + 'Rotation{:.1f}.png'.format(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSiqebIFm0d"
      },
      "source": [
        "Random Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZnTTCMUF-TO"
      },
      "source": [
        "translate = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    new_irm, new_mask  = translate((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random translation')\n",
        "    fig.savefig(save_path + 'Translation_{}.png'.format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWO-77u0F-1j"
      },
      "source": [
        "Random Zoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q4YHSk8GJcF"
      },
      "source": [
        "zoom = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    (new_irm, new_mask)  = zoom((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random zoom ')\n",
        "    fig.savefig(save_path + 'Zoom_{}.png'.format(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fytm3C4GbZU"
      },
      "source": [
        "All transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNzPoFz5GbLP"
      },
      "source": [
        "affine_transform = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    (new_irm, new_mask)  = affine_transform((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Rotation Translation Zoom')\n",
        "    fig.savefig(save_path + 'All_transforms{}.png'.format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaqqV3VeGngd"
      },
      "source": [
        "## 7.b. Entraînement avec data augmentation\n",
        "\n",
        "Relancer un nouvel entraînement avec les techniques d'augmentation de données dans `transformation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqiwTM46GnQm"
      },
      "source": [
        "transforms_list = [AffineTransform(theta=15, max_translation=15, max_zoom=0.3),\n",
        "                   AxialFlip(), RandomRotation90(), RandomCrop((64, 64))\n",
        "                   ]\n",
        "\n",
        "transformation = torchvision.transforms.Compose(transforms_list)\n",
        "\n",
        "\n",
        "train_Dataset = SegmentationDataset(train_IDs, data_path=data_path,\n",
        "                                    transform=transformation\n",
        "                                    )\n",
        "\n",
        "val_Dataset = SegmentationDataset(val_IDs, data_path=data_path,\n",
        "                                  transform=transformation\n",
        "                                  )\n",
        "\n",
        "test_Dataset = SegmentationDataset(test_IDs, data_path=data_path,\n",
        "                                  transform=None\n",
        "                                  )\n",
        "\n",
        "train_loader_data_augment = torch.utils.data.DataLoader(train_Dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "val_loader_data_augment = torch.utils.data.DataLoader(val_Dataset,\n",
        "                                         batch_size=batch_size, drop_last=True)\n",
        "\n",
        "test_loader_data_augment = torch.utils.data.DataLoader(test_Dataset,\n",
        "                                         batch_size=1, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsSXipSP3R8"
      },
      "source": [
        "learning_rate = 1e-4\n",
        "image_size = (96, 96)\n",
        "n_modalities = 4\n",
        "n_labels = 4\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "print_frequency = 5\n",
        "save_frequency = 10\n",
        "save_model = True\n",
        "tumor_percentage = 0.5\n",
        "tensorboard = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PjSlaLVgQnVL"
      },
      "source": [
        "model = \"\"\"Complete here\"\"\" # Create model\n",
        "model.cuda() # move model to GPU\n",
        "\n",
        "criterion = \"\"\"Complete here\"\"\" # Choose loss function\n",
        "optimizer = \"\"\"Complete here\"\"\" # Choose optimizer\n",
        "\n",
        "# Keep logs of training metrics. To visualize with tensorbard.\n",
        "log_dir = tensorboard_folder + session_name + '/'\n",
        "if not os.path.isdir(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "    print(session_name)\n",
        "\n",
        "    # train for one epoch\n",
        "    model.train()\n",
        "    print('Training')\n",
        "    train_loop(train_loader_data_augment, model, criterion,\n",
        "               optimizer, writer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    print('Validation')\n",
        "    with torch.no_grad():  # Don't compute gradients\n",
        "        model.eval()       # Deactivate any BarchNormalization or Dropout layer\n",
        "        val_loss = train_loop(val_loader_data_augment, model, criterion,\n",
        "                              optimizer, writer, epoch)\n",
        "    # Save model and otpimizer states\n",
        "    # Saving the optimizer state allows to do further fine tuning later.\n",
        "    if save_model and epoch % save_frequency == 0:\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                         'val_loss': val_loss,\n",
        "                         'optimizer': optimizer.state_dict()}, model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xfMg6ZI__HT"
      },
      "source": [
        "## 7.c. Evaluation du modèle\n",
        "\n",
        "Exécutez le code suivant pour évaluer le modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PESqk1-0_9f-"
      },
      "source": [
        "test_path = original_data_path\n",
        "patients = [os.path.basename(p) for p in glob(test_path + \"*\")]\n",
        "patient = patients[0]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader_data_augment, model, batch_size=batch_size)\n",
        "\n",
        "\n",
        "predict_mask = reconstruct_patient(preds, patient)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Model prediction\")\n",
        "plt.imshow(np.argmax(predict_mask[50, ...], axis=0))\n",
        "plt.show()\n",
        "\n",
        "print(\"Mask shape:\", predict_mask.shape)\n",
        "\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n",
        "print(\"Resized mask shape:\", predict_mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gWzEu7zCXqj"
      },
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model, batch_size=batch_size)\n",
        "\n",
        "for patient in patients:\n",
        "    # Path to original image\n",
        "    patient_folder = os.path.join(test_path,patient)\n",
        "    # Open image\n",
        "    orig_image = sitk.ReadImage(os.path.join(patient_folder,\n",
        "                                            patient  + '_seg.nii.gz' ))\n",
        "    # Convert image to numpy array\n",
        "    orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "    # Reconstruct the whole patient predicted mask\n",
        "    predict_mask = reconstruct_patient(preds, patient)\n",
        "    predict_mask = get_mask2original_shape(predict_mask)\n",
        "\n",
        "    print('*********** {} ***********'.format(patient))\n",
        "    scores = evalAllSample(predict_mask, orig_mask)\n",
        "    print(scores)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "    et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "    tc_dice_list.append(scores.loc['Dice', 'tc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crUzG4gYCaaC"
      },
      "source": [
        "print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n",
        "print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmMD4ERVcNBl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}